{
    "home":"home",
    "about":"about",
    "skills":"skills",
    "portfolio":"portfolio",
    "contact":"contact",
    "home__title": "Hi, I'm Zhiye Zhao<br>(Caesar)",
    "home__subtitle":"Robotics Engineer | AI Researcher",
    "home__description":"Engineer with hands-on experience in robotics and AI, dedicated to delivering innovative, high-quality solutions.",
    "home__contact":"Contact Me",
    "home1__subtitle":"Robotics",

    "home__scroll-name":"Scroll down",
    "about__title":"About Me",
    "about__subtitle":"Brief Introduction",
    "about__description": "With a solid background in robotics, I specialize in motion control, path planning, state estimation, and multi-sensor fusion. My expertise enables me to independently develop and deploy intelligent robotic systems across diverse platforms.",
    "about__description2": "Currently, my research focuses on embodied intelligence, where I explore how learning-based methods‚Äîsuch as reinforcement learning and perception-driven decision models‚Äîcan enhance robot autonomy and adaptability.",
    "about__description3": "I aim to bring intelligent robotics into real-world applications in industrial and service settings, driving innovation through practical deployment and interdisciplinary collaboration.",
    "about__info-name1":"Years of <br /> experience",
    "about__info-name2":"Completed <br /> projects",
    "about__info-name3":"Companies <br /> worked",
    "download":"Download CV",

    "about__hobby_title": "Personal Interests",
    "hobbies__philosophy": "Philosophy",
    "hobbies__math": "Mathematics",
    "hobbies__bjj": "Brazilian Jiu-Jitsu",
    "hobbies__stick": "Kali/Arnis/Eskrima",
    "hobbies__guqin": "Guqin",
    "hobbies__reading": "Literature",

    "skills__title":"Technical Skills",
    "skills__subtitle":"My technical level",
    "skills__years":"More than 2 years",
    "skills__title2":"Artificial Intelligence",
    "skills__years2":"More than1 years",
    "timeline__present": "Present",

    "skills__title3": "Soft Skills",
    "skills__years3": "Improved through projects and teamwork",

    "softskills__sustainability": "Sustainable Engineering Thinking",
    "softskills__intercultural": "Intercultural Communication",
    "softskills__problem_solving": "Analytical Problem Solving",
    "softskills__leadership": "Project Leadership",
    "softskills__time": "Time Management",
    "softskills__view_report": "View Report",
    "softskills__level_proficient": "Proficient",
    "softskills__level_skilled": "Skilled",
    "softskills__level_competent": "Competent",

    "qualification__title":"Qualification",
    "qualification__subtitle":"My personal journey",
    "education":"Education",
    "work":"Work",
    "qualification1__title":"Mechanical Design Manufacture and Automation",
    "qualification1__subtitle":"Hunan Institute of Technology",
    "qualification2__title":"Master of Professional Engineering, Robotics ",
    "qualification2__subtitle":"University of Technology Sydney (UTS)",
    "qualification3__title":"Embodied Intelligence",
    "qualification3__subtitle":"Self-Study",

    "qualification4__title":"Teaching Assistant & Research Assistant (Part time)",
    "qualification4__subtitle":"Remote, Part-time",


    "qualification5__title":"Research & Development Engineer (Intern)",
    "qualification5__subtitle":"Optik Consultancy, Sydney",

    "portfolio__title":"Portfolio",
    "portfolio__subtitle":"Most recent works",

  "portfolio_asap__title": "ASAP/PBHC Whole-Body Control",
  "portfolio_asap__description": "Built on ASAP (Adaptive Skill Acquisition Policy) and PBHC (Physics-Based Hierarchical Control). Complex motions are decomposed into skill primitives with physical constraints; RL + simulation enable precise, stable imitation validated on hardware.",
  "portfolio_host__title": "HoST: Multi-Posture Standing Control",
  "portfolio_host__description": "RL + physics-based HoST framework for autonomous standing from diverse postures. Multi-layer rewards and reward curriculum train a policy for stable standing and posture transitions; deployed on real hardware.",
  "portfolio_tron1a__title": "Tron1A Point-Foot Biped: Complex Terrain Locomotion",
  "portfolio_tron1a__description": "RL policy trained in physics simulation for balance, gait control, and terrain adaptation on steps and uneven ground with a high-DoF, underactuated system.",

    "portfolio2__title":"Leader-Follower Formation Control with MPC",
    "portfolio2__description":"This project implements a leader-follower formation control system using Model Predictive Control (MPC) in MATLAB. It enables multiple robots to track a moving leader while maintaining formation and avoiding obstacles. I developed the core MPC controller and formation logic, ensuring robust coordination in dynamic environments.",
    "mpc_title": "Leader-Follower Formation Control with MPC",
    "mpc_goalTitle": "Project Overview",
    "mpc_goalDesc": "This project implements a centralized leader-follower formation control system using Model Predictive Control (MPC) in MATLAB. The system enables a team of robots to maintain geometric formation, track a moving leader, and avoid obstacles in dynamic environments. I was responsible for developing the core MPC controller and coordination logic. The approach demonstrates strong robustness against disturbances and serves as a scalable foundation for future multi-agent collaboration.",
    "mpc_demoTitle": "Demonstration",
    "mpc_demoDesc": "The video below demonstrates how follower robots maintain coordinated formation using MPC, even when encountering sharp turns and dynamic obstacles.",
    "mpc_imageDesc": "The figures below show the complete motion trajectories of the robot team after executing formation control. Despite dense obstacle layouts, the system maintained stable formation and effective collision avoidance, validating the robustness of the proposed method.",
    "mpc_methodsTitle": "Core Techniques",
    "mpc_method1": "‚úì Designed a centralized MPC framework for real-time formation control",
    "mpc_method2": "‚úì Encoded formation geometry and tracking objectives into the cost function",
    "mpc_method3": "‚úì Integrated collision avoidance using inter-agent and obstacle constraints",
    "mpc_method4": "‚úì Verified system stability through simulation in MATLAB under complex scenarios",
    "mpc_githubLink": "üíª View Code on GitHub",
    "mpc_back": "‚Üê Return to Portfolio",
    
    "portfolio3__title": "State Estimation for the Tripedal Climbing Robot",
    "portfolio3__description": "This project explores state estimation for a tripedal climbing robot. An EKF-based approach fuses IMU and encoder data to estimate body position, velocity, and orientation in real time, enabling stable climbing and control.",
    "parcli_title": "Tripedal Climbing Robot",
    "parcli_goalTitle": "Project Overview",
    "parcli_goalDesc": "This project investigates the state estimation and control of a custom-built tripedal climbing robot designed for vertical surface traversal. An Extended Kalman Filter (EKF) is employed to fuse IMU and encoder data for real-time estimation of position, velocity, and orientation. These estimates support dynamic stability, foot placement planning, and closed-loop motion control.",
    "parcli_demoTitle": "Demonstration",
    "parcli_demoDesc": "The following video demonstrates the robot's behavior in simulation, including trajectory tracking, posture control, and climbing adaptation. This validates the estimation and control pipeline in a dynamic climbing scenario.",
    "parcli_realIntro": "A physical prototype of the tripedal robot was also constructed to evaluate the estimation method on hardware. The image below shows the assembled platform equipped with onboard sensors and actuators used in real-world testing.",
    "parcli_methodsTitle": "Core Techniques",
    "parcli_method1": "‚úì Applied an Extended Kalman Filter (EKF) for estimating position, velocity, and orientation in real time",
    "parcli_method2": "‚úì Fused IMU and encoder data to improve robustness under dynamic climbing conditions",
    "parcli_method3": "‚úì Built customized dynamic and kinematic models for tripedal locomotion",
    "parcli_method4": "‚úì Conducted simulation and visualization using MATLAB and PyDrake to validate estimation accuracy",
    "parcli_back": "‚Üê Return to Portfolio",

    "portfolio1__title":"Multi-Robot Navigation System",
    "portfolio1__description":"A ROS-based navigation system designed for multiple TurtleBot3 robots operating in shared indoor environments. It features autonomous path planning, AMCL-based localization, and real-time sensor fusion. The system integrates Dijkstra and DWA planning algorithms and has been validated through both simulation and real-world testing.",
    "multirobot_title": "Multi-Robot Navigation System",
    "multirobot_goalTitle": "Project Overview",
    "multirobot_goalDesc": "This project develops a ROS-based navigation system for multiple TurtleBot3 robots operating in shared indoor environments. It enables real-time collaborative path planning, AMCL-based localization, and multi-sensor fusion, allowing autonomous and collision-free navigation.",
    "multirobot_demoTitle": "Demonstration",
    "multirobot_demoDesc": "The following video demonstrates coordinated navigation of multiple TurtleBot3 robots in a shared indoor environment, including localization, planning, and obstacle avoidance in real time.",
    "multirobot_methodsTitle": "Core Techniques",
    "multirobot_method1": "‚úì Centralized task assignment using global occupancy map",
    "multirobot_method2": "‚úì Global planning with Dijkstra, local planning with DWA",
    "multirobot_method3": "‚úì Real-time localization with AMCL and laser scan matching",
    "multirobot_method4": "‚úì Multi-robot coordination using ROS namespaces and tf tree separation",
    "multirobot_downloadPDF": "üìÑ View Report",
    "multirobot_githubLink": "üíª View Code on GitHub",
    "multirobot_back": "‚Üê Return to Portfolio",

    "portfolio5__title":"Soil Moisture Estimation via EKF-Based Sensor Fusion",
    "portfolio5__description":"An EKF-based sensor fusion system for MPT AgTech‚Äôs platform, developed through international collaboration. It delivers stable, real-time soil moisture estimation despite environmental noise and hardware limitations.",    
    "soilmoisture_title": "Soil Moisture Estimation System",
    "soilmoisture_goalTitle": "Project Overview",
    "soilmoisture_goalDesc": "This project presents a soil moisture sensing system developed for MPT AgTech‚Äôs autonomous seeding platform during my internship at Optik Consultancy. I independently designed the EKF-based filtering pipeline for real-time estimation, while working closely with engineers from multiple countries. The system demonstrates not only technical robustness under field conditions, but also the value of cross-cultural collaboration in delivering impactful agricultural solutions.",
    "soilmoisture_demoTitle": "Demonstration",
    "soilmoisture_demoDesc": "The video below showcases our team‚Äôs real-time demonstration of the EKF-based moisture estimation system. Engineers from diverse backgrounds collaborated throughout the project, combining expertise to deliver a robust, field-ready solution that was well received by MPT AgTech.",
    "soilmoisture_feedbackIntro": "The image below is a <a href='https://www.linkedin.com/feed/update/urn:li:activity:7295927342361628672/?actorCompanyId=75593246' target='_blank'>LinkedIn post</a> shared by an engineer at <a href='https://mpt.ag/' target='_blank'>MPT AgTech</a>, highlighting the performance and team effort behind this project. It reflects the recognition our solution received after the demonstration, and lists all core contributors, including myself.",
    "soilmoisture_methodsTitle": "Core Techniques",
    "soilmoisture_method1": "‚úì Designed and implemented a real-time EKF-based soil moisture estimation pipeline",
    "soilmoisture_method2": "‚úì Filtered sensor signals under real-world noise and environmental fluctuations",
    "soilmoisture_method3": "‚úì Calibrated and tuned the filter for hardware non-idealities and field deployment",
    "soilmoisture_method4": "‚úì Validated and praised by MPT AgTech engineers in live demonstration",
    "soilmoisture_back": "‚Üê Return to Portfolio",


    "pointcloud__title": "3D Point Cloud Perception and Surface Modeling",
    "pointcloud__description": "A complete pipeline for 3D point cloud classification and surface modeling using unsupervised and supervised learning, regression, and uncertainty estimation.",
    "pointcloud_overview": "Project Overview",
    "pointcloud_overview_desc": "This project independently develops a comprehensive pipeline for semantic classification and terrain reconstruction of 3D point cloud data. It integrates unsupervised clustering (K-Means), dimensionality reduction (PCA), supervised learning (SVM), and regression modeling (Linear Regression and Gaussian Process Regression) with uncertainty estimation. This solution enables accurate environmental perception essential for robotics, autonomous navigation, and intelligent mapping applications.",
    "pointcloud_demo": "Demonstration",
    "pointcloud_demo_desc": "The following visualizations illustrate each critical stage of the implemented pipeline, from initial segmentation and feature extraction to high-accuracy classification and reliable surface modeling.",
    "pointcloud_classification": "Point Cloud Classification",
    "pointcloud_classification_desc": "This stage focuses on robust semantic classification through a combination of unsupervised clustering, dimensionality reduction, and supervised machine learning methods.",
    "pointcloud_kmeans": "K-Means clustering effectively segments the raw 3D data based on spatial coordinates and RGB color values, enabling accurate region separation without prior labeling.",
    "pointcloud_pca": "Principal Component Analysis (PCA) identifies dominant geometric directions within clusters, significantly enhancing the clarity and efficiency of subsequent feature extraction.",
    "pointcloud_svm_train": "An optimized Support Vector Machine (SVM) classifier achieves exceptional accuracy, demonstrating perfect (AUC = 1.0) classification performance on the training dataset.",
    "pointcloud_svm_test": "The classifier maintains outstanding generalization performance with an AUC of 0.999 on unseen test data, confirming robustness and reliability.",
    "pointcloud_modeling": "Surface Modeling",
    "pointcloud_modeling_desc": "Here, continuous surface reconstruction and uncertainty quantification are performed to ensure precise and reliable terrain modeling.",
    "pointcloud_gpr": "Gaussian Process Regression (GPR) provides smooth and accurate terrain predictions, accompanied by uncertainty estimates (confidence intervals), essential for decision-making under uncertainty.",
    "pointcloud_uncertainty": "Analysis reveals a strong correlation between predicted uncertainties and actual errors, validating the effectiveness and reliability of the GPR model calibration.",
    "pointcloud_linear_r2": "Linear regression shows high R¬≤ scores particularly in structurally simpler regions (walls and floors), highlighting the model's suitability for planar surface reconstruction.",
    "pointcloud_methods": "Methods",
    "pointcloud_method1": "‚úì Unsupervised spatial-color segmentation using K-Means clustering.",
    "pointcloud_method2": "‚úì Dimensionality reduction via PCA for effective feature extraction.",
    "pointcloud_method3": "‚úì Robust supervised classification using SVM with extensive evaluation metrics (ROC-AUC, F1, Confusion Matrix).",
    "pointcloud_method4": "‚úì Surface reconstruction with segmented Linear Regression models.",
    "pointcloud_method5": "‚úì Probabilistic terrain modeling via Gaussian Process Regression including uncertainty quantification.",
    "pointcloud_method6": "‚úì Hyperparameter optimization of GPR models using Maximum Likelihood Estimation (MLE).",
    "pointcloud_view_classification": "üìÑ View Classification Report",
    "pointcloud_view_modeling": "üìÑ View Surface Modeling Report",
    "pointcloud_view_code": "üíª View Code on GitHub",
    "pointcloud_back": "‚Üê Return to Portfolio",

    "portfolio6__title": "Autonomous Navigation via Deep Q-Network",
    "portfolio6__description": "This project implements a Deep Q-Network (DQN) agent for autonomous driving in a simulated PyBullet environment. The agent learns to navigate towards dynamic goals while avoiding obstacles, with support for training, evaluation, and animated diagnostics. Built on top of the simple-car-env-template and extended independently.",
    "dqn_overview_title": "Project Overview",
    "dqn_overview_desc": "This project independently implements a Deep Q-Network (DQN) agent for autonomous navigation in a 2D PyBullet simulation. The agent learns goal-reaching behavior under uncertainty using value-based reinforcement learning with discrete motion commands, reward shaping, and exploration decay. The environment extends the simple-car-env-template and includes visual diagnostics for training evaluation. Developed as part of an advanced robotics module, this project demonstrates practical skills in learning-based control, simulation engineering, and agent diagnostics.",
    "dqn_demo_title": "Demonstration",
    "dqn_demo_desc": "This section presents a visual walkthrough of the learning process and policy behavior, highlighting both theoretical underpinnings and practical results.",
    "dqn_demo_mdp": "The Markov Decision Process (MDP) framework provides the foundation for value-based reinforcement learning methods like DQN.",
    "dqn_demo_eval": "Policy evaluation shows the agent navigating efficiently toward the goal while avoiding dynamic obstacles.",
    "dqn_demo_training": "The reward curve demonstrates steady policy improvement over training episodes, validating the agent's learning progression.",
    "dqn_demo_epsilon": "The Œµ-decay curve reflects the agent‚Äôs shift from exploratory to exploitative behavior as training proceeds.",
    "dqn_methods_title": "Methods",
    "dqn_method_1": "‚úì Discrete DQN agent with 9 control actions and a multilayer perceptron (MLP) policy network",
    "dqn_method_2": "‚úì Simulation environment extended from simple-car-env-template with dynamic obstacle generation",
    "dqn_method_3": "‚úì Reward shaping based on goal proximity, collision penalties, and sparse terminal rewards",
    "dqn_method_4": "‚úì Epsilon-greedy exploration with exponential decay for efficient policy convergence",
    "dqn_method_5": "‚úì Evaluation based on success thresholds, cumulative rewards, and behavioral visualization",
    "dqn_view_report": "üìÑ View Report",
    "dqn_view_code": "üíª View Code on GitHub",
    "dqn_back_to_portfolio": "‚Üê Return to Portfolio",

    "portfolio7__title": "Single-Leg Jump Control for the G1 Humanoid Robot",
    "portfolio7__description": "This project implements single-leg jumping for the G1 humanoid robot in Isaac Gym. Using reinforcement learning (PPO) with a customized reward structure, the robot learns dynamic jumping motions while maintaining balance and landing stability. The project showcases skills in simulation control, motion optimization, and RL training.",
    "g1jump_title": "Single-Leg Jump Control for the G1 Humanoid Robot | Caesar Zhao",
    "g1jump_overview_title": "Project Overview",
    "g1jump_overview_desc": "This project implements single-leg jumping for the G1 humanoid robot using reinforcement learning (PPO) in Isaac Gym. The robot learns dynamic and stable jumping motions through customized reward structures and policy optimization. The results demonstrate effective learning and stable motion control in simulation.",
    
    "g1jump_demo_title": "Demonstration",
    "g1jump_demo_desc": "The following videos show the single-leg jumping motion and group performance of G1 humanoid robots after training.",
    "g1jump_demo_group": "Group demonstration after 25,700 steps of training.",
    "g1jump_demo_single": "Single-leg jumping motion demonstration.",
  
    "g1jump_data_title": "Training Results",
    "g1jump_data_desc": "The following figures present the training dynamics and learning results for the single-leg jumping task.",
    "g1jump_data_episode_length": "Average episode length during training, showing motion stabilization.",
    "g1jump_data_entropy": "Entropy loss decreasing, indicating policy convergence.",
    "g1jump_data_lower_body": "Lower body control error reducing and stabilizing over time.",
    "g1jump_data_reward": "Mean reward showing steady improvement during training.",
    "g1jump_data_upper_body": "Upper body control error stabilizing through training.",
    "g1jump_data_3point": "Norm of 3-point keypoints error during jumping, indicating improvement in motion precision.",
  
    "g1jump_methods_title": "Methods",
    "g1jump_method_1": "‚úì Proximal Policy Optimization (PPO) with customized reward shaping for jumping behavior.",
    "g1jump_method_2": "‚úì Simulation conducted in Isaac Gym with physics-based dynamics.",
    "g1jump_method_3": "‚úì Action-space design focused on torque control and jump height optimization.",
    "g1jump_method_4": "‚úì Curriculum learning strategy: starting from small hops and scaling up jump difficulty.",
    "g1jump_method_5": "‚úì Evaluation based on motion stability, jumping height, and landing control.",
  
    "g1jump_view_report": "üìÑ View Report",
    "g1jump_view_code": "üíª View on GitHub",
    "g1jump_back_to_portfolio": "‚Üê Return to Portfolio",

    "contact__title":"Contact me",
    "contact__subtitle":"Get in touch",
    "tel":"Tel",
    "tel__number":"+61 493 325 317",
    "email":"E-mail",
    "email__address":"caesar1457@gmail.com",
    "location":"Location",
  "location__detail":"HangZhou , China",

  "asap_title": "ASAP/PBHC Whole-Body Control",
  "asap_overview_title": "Project Overview",
  "asap_overview_desc": "This project builds on the ASAP (Adaptive Skill Acquisition Policy) and PBHC (Physics-Based Hierarchical Control) frameworks to achieve whole-body control of a high-DoF humanoid (Unitree G1). Using reinforcement learning and physics simulation, complex motions are decomposed into skill primitives and combined with physical constraints to enable stable, precise motion imitation, with successful deployment on real hardware.",
  "asap_methods_title": "Core Techniques",
  "asap_method1": "‚úì Operational-space control with task-space tracking and null-space posture regulation",
  "asap_method2": "‚úì Hierarchical task prioritization with contact-consistent dynamics",
  "asap_method3": "‚úì Smooth task transitions across manipulation and locomotion behaviors",
  "asap_back": "‚Üê Return to Portfolio",
  "asap_demo_title": "Demonstration",
  "asap_demo_desc": "Short clips showing whole-body control tracking during kicking behaviors.",
  "asap_kick_combo_caption": "Continuous Front Kicks",
  "asap_side_kick_caption": "Side Kick",
  "asap_sword_caption": "Sword Dance",
  "asap_boxing_caption": "Boxing",
  "asap_motivation_title": "Motivation & Scope",
  "asap_motivation_desc": "Humanoid control often requires tracking multiple, sometimes conflicting, objectives under intermittent contact. ASAP/PBHC combines operational-space control with hierarchical task composition and contact-consistent dynamics to enable smooth whole-body behaviors across manipulation and locomotion.",
  "asap_contribs_title": "My Contributions",
  "asap_contrib1": "‚úì Defined a compact task set (CoM, torso, end-effector, posture) with consistent task frames and units",
  "asap_contrib2": "‚úì Implemented priority blending and gain scheduling for contact switching and motion phases",
  "asap_contrib3": "‚úì Integrated contact-consistent dynamics and validated on high-velocity kicking motions",
  "asap_results_title": "Results",
  "asap_result1": "‚úì Stable task tracking with smooth transitions across stance and swing phases",
  "asap_result2": "‚úì Robustness to contact switches and rapid joint accelerations without noticeable torque spikes",
  "asap_result3": "‚úì Reproducible behaviors across sessions and scenarios (see demo clips)",

  "host_title": "HoST: Multi-Posture Standing Control for Humanoid Robots",
  "host_overview_title": "Project Overview",
  "host_overview_desc": "This project is based on the HoST (Humanoid Standing-up Task) framework to enable autonomous standing from diverse initial postures for a humanoid robot. Leveraging reinforcement learning with physics simulation, we design a multi-layer reward structure and an action reward curriculum to train a policy that controls full-body joints for stable standing and posture transitions.",
  "host_methods_title": "Core Techniques",
  "host_method1": "‚úì Operational-space tracking with robust feedback",
  "host_method2": "‚úì Multi-contact handling and task blending",
  "host_method3": "‚úì Real-time implementation with modular task definitions",
  "host_back": "‚Üê Return to Portfolio",
  "host_demo_title": "Demonstration",
  "host_demo_desc": "Ground-contact tracking test with operational-space control.",
  "host_ground_caption": "Ground get-up",
  "host_chair_caption": "Chair get-up",
  "host_platform_caption": "Platform get-up",
  "host_prone_caption": "Prone get-up",
  "host_wall_caption": "Wall get-up",
  "host_motivation_title": "Motivation & Scope",
  "host_motivation_desc": "HoST targets high-fidelity operational-space tracking for whole-body control with clear task decomposition, real-time performance, and easy composition of multi-contact behaviors.",
  "host_contribs_title": "My Contributions",
  "host_contrib1": "‚úì Designed task interfaces and clean API for composing tracking objectives",
  "host_contrib2": "‚úì Implemented ground-contact tracking modules with configurable constraints",
  "host_contrib3": "‚úì Benchmarked tracking stability and responsiveness under perturbations",
  "host_results_title": "Results",
  "host_result1": "‚úì Accurate operational-space tracking with smooth joint motions",
  "host_result2": "‚úì Stable behavior across varying contact conditions on the ground",
  "host_result3": "‚úì Modular tasks that can be extended to manipulation or locomotion",

  "tron_title": "Tron1A Point-Foot Biped Locomotion on Complex Terrain",
  "tron_overview_title": "Project Overview",
  "tron_overview_desc": "This project enables autonomous locomotion of the Tron1A point-foot biped on complex terrain (including steps and uneven ground). Using reinforcement learning with physics simulation, a policy is trained to maintain balance, control gait, and adapt to terrain variations in a high-DoF, underactuated system.",
  "tron_methods_title": "Core Techniques",
  "tron_method1": "‚úì State estimation with IMU and kinematics for floating-base pose",
  "tron_method2": "‚úì Gait generation with ZMP/CoM planning and phase scheduling",
  "tron_method3": "‚úì Whole-body control for stance and swing with contact constraints",
  "tron_back": "‚Üê Return to Portfolio",
  "tron_demo_title": "Demonstration",
  "tron_demo_desc": "Traversals across varied terrains highlighting balance and adaptability.",
  "tron_allterrain1_caption": "Complex Terrain",
  "tron_allterrain2_caption": "Complex Terrain"
  ,
  "tron_motivation_title": "Motivation & Scope",
  "tron_motivation_desc": "Point-foot bipeds lack ankle actuation at the foot, demanding precise state estimation, foot placement, and whole-body coordination. This project develops a practical locomotion pipeline for Tron1A across diverse terrains.",
  "tron_contribs_title": "My Contributions",
  "tron_contrib1": "‚úì Implemented a lightweight estimator combining IMU and leg kinematics for floating-base pose",
  "tron_contrib2": "‚úì Built a gait generator with CoM/ZMP planning and phase scheduling for stance/swing",
  "tron_contrib3": "‚úì Applied whole-body control with contact constraints for stable ground interactions",
  "tron_results_title": "Results",
  "tron_result1": "‚úì Consistent traversals over mixed terrains with balanced CoM motion",
  "tron_result2": "‚úì Reliable transitions between gait phases without foot scuffing",
  "tron_result3": "‚úì Video evidence shows robustness to moderate disturbances"
}